import pandas as pd
import requests
from tqdm import tqdm


# function to collect the process ids from the hdf storage
def collect_process_ids(hdf_name_results: str) -> tuple:
    """Function to collect all process ids from the downloaded data.

    Args:
        hdf_name_results (str): Path to the hdf storage that's generated by the data download

    Returns:
        tuple: Returns a tuple of lists (all_process_ids, unique_process ids)
        only the unique process ids are needed for the data download, all process ids are needed to rebuild
        the final dataset.
    """

    # read the results from hdf storage
    unsorted_results = pd.read_hdf(hdf_name_results)
    process_ids = unsorted_results["process_id"]

    # remove duplicates and empty strings from process ids
    unique_process_ids = list(set([idx for idx in process_ids if idx != ""]))

    # return the ids
    return process_ids, unique_process_ids


# main functio to run the additional data download
def main(hdf_name_results: str) -> None:
    """Main function to run the additional data download. Downloads additional data
    for all public process ids, saves the to hdf first and finally add them to the
    results.

    Args:
        hdf_name_results (str): Path to the hdf storage thats generated by the data download.
    """
    # collect all process ids first
    process_ids, unique_process_ids = collect_process_ids(hdf_name_results)

    urls = [
        "https://portal.boldsystems.org/record/{}".format(idx)
        for idx in unique_process_ids
    ]


main(
    "C:\\Users\Dominik\\Documents\\GitHub\\BOLDigger3\\tests\\test_1000_result_storage.h5.lz"
)
